{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d87c1b2-3beb-4f37-a4d5-4d712be2f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 22 02:00:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.16              Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  |   00000000:15:00.0  On |                  Off |\n",
      "| 30%   45C    P2             66W /  230W |    5598MiB /  24564MiB |     35%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               On  |   00000000:99:00.0 Off |                  Off |\n",
      "| 30%   45C    P0             61W /  230W |    5598MiB /  24564MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             507      C   /python3.12                           N/A      |\n",
      "|    1   N/A  N/A             507      C   /python3.12                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbd282-bf30-4184-92d7-7d332c743c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50da93e7-2b3a-4126-a1b6-fa574ed0aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText \n",
    "import torch \n",
    "\n",
    "model_path = \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\" \n",
    "processor = AutoProcessor.from_pretrained(model_path) \n",
    "model = AutoModelForImageTextToText.from_pretrained(model_path, torch_dtype=torch.bfloat16, _attn_implementation=\"flash_attention_2\").to(\"cuda\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb98ac5a-7cdb-454c-8c01-ac6dc7300336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 22 01:45:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.16              Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  |   00000000:15:00.0  On |                  Off |\n",
      "| 30%   43C    P8             16W /  230W |    5556MiB /  24564MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               On  |   00000000:99:00.0 Off |                  Off |\n",
      "| 30%   43C    P8             13W /  230W |    5556MiB /  24564MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           11909      C   /python3.12                           N/A      |\n",
      "|    1   N/A  N/A           11909      C   /python3.12                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2df3c3-79fd-4190-9c43-f9a1982ee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"role\": \"user\", \"content\": [ {\"type\": \"video\", \"path\": \"Music.mp4\"}, {\"type\": \"text\", \"text\": \"Describe this video in detail\"} ] },]\n",
    "\n",
    "inputs = processor.apply_chat_template( messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\", ).to(model.device, torch.bfloat16) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83abd810-abe5-44c7-89c8-4187594ce326",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=564) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbac5393-0ca5-4dca-aea5-5e5c529539c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts = processor.batch_decode( generated_ids, skip_special_tokens=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0bc92d-c636-4593-9203-4c7627e289d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: You are provided the following series of sixty-four frames from a 0:02:22 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:03:\\nFrame from 00:05:\\nFrame from 00:07:\\nFrame from 00:09:\\nFrame from 00:12:\\nFrame from 00:14:\\nFrame from 00:16:\\nFrame from 00:18:\\nFrame from 00:21:\\nFrame from 00:23:\\nFrame from 00:25:\\nFrame from 00:27:\\nFrame from 00:29:\\nFrame from 00:32:\\nFrame from 00:34:\\nFrame from 00:36:\\nFrame from 00:38:\\nFrame from 00:41:\\nFrame from 00:43:\\nFrame from 00:45:\\nFrame from 00:47:\\nFrame from 00:50:\\nFrame from 00:52:\\nFrame from 00:54:\\nFrame from 00:56:\\nFrame from 00:58:\\nFrame from 01:01:\\nFrame from 01:03:\\nFrame from 01:05:\\nFrame from 01:07:\\nFrame from 01:10:\\nFrame from 01:12:\\nFrame from 01:14:\\nFrame from 01:16:\\nFrame from 01:18:\\nFrame from 01:21:\\nFrame from 01:23:\\nFrame from 01:25:\\nFrame from 01:27:\\nFrame from 01:30:\\nFrame from 01:32:\\nFrame from 01:34:\\nFrame from 01:36:\\nFrame from 01:39:\\nFrame from 01:41:\\nFrame from 01:43:\\nFrame from 01:45:\\nFrame from 01:47:\\nFrame from 01:50:\\nFrame from 01:52:\\nFrame from 01:54:\\nFrame from 01:56:\\nFrame from 01:59:\\nFrame from 02:01:\\nFrame from 02:03:\\nFrame from 02:05:\\nFrame from 02:08:\\nFrame from 02:10:\\nFrame from 02:12:\\nFrame from 02:14:\\nFrame from 02:17:\\nFrame from 02:19:\\nFrame from 02:21:\\n\\nDescribe this video in detail\\nAssistant: The video opens with a serene view of a lush, green forest, transitioning to a panoramic view of a mountainous landscape under a clear blue sky. The camera then shifts to a closer view of the mountains, highlighting the dense forest and the expansive green field below. A solitary figure appears in the distance, walking towards the camera, eventually standing in the center of the frame, surrounded by the natural beauty of the mountains and forest. The person, dressed in a black top and a long, gray skirt, stands still, looking out at the expansive view. The camera zooms in on the person, capturing their profile and the serene environment. The person then moves closer to the camera, standing in the center of the frame, with the mountains and forest in the background. The person appears to be speaking or singing, with their arms outstretched, adding a sense of movement and emotion to the scene. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89da4085-cb45-4c88-b932-fa41446f5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from transformers.image_utils import load_image \n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca63aa05-0416-4839-925d-89d5f8863d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c7ce48c-23b0-4290-859e-88bd1f07d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "image1 = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "image2 = load_image(\"https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg\")\n",
    "image3=  Image.open('invoice.png').convert('RGB')\n",
    "\n",
    "prompt=\"\"\"\n",
    "Extract the item names from this invoice. please do not include unit price and total amount. provide the name in list\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6987c22b-2ffe-4ad9-9fad-1c80580f1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor and model\n",
    "model_path = \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\" \n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "739e728f-d5b2-4a2f-b4dc-c9e49678359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffda31ce-83b4-47eb-be5e-21e10dfd8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the three images?\"}\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ac159ec-25cd-4376-bb08-078945e14e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image1, image2, image3], return_tensors=\"pt\")\n",
    "inputs = inputs.to(model.device, torch.bfloat16) \n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=500) \n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19599dda-a9f6-4208-a8bb-1b3c3610fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Can you describe the three images?\n",
      "Assistant: The first image is a photograph of the Statue of Liberty in New York City, with a city skyline in the background. The second image is a photograph of a bee on a pink flower, with other flowers in the background. The third image is an invoice from a company called East Repair Inc., with a list of items and their prices.\n"
     ]
    }
   ],
   "source": [
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95a171-e4c2-472a-831e-e059bfdf1ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
