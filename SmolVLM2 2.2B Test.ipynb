{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d87c1b2-3beb-4f37-a4d5-4d712be2f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 22 02:00:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.16              Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  |   00000000:15:00.0  On |                  Off |\n",
      "| 30%   45C    P2             66W /  230W |    5598MiB /  24564MiB |     35%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               On  |   00000000:99:00.0 Off |                  Off |\n",
      "| 30%   45C    P0             61W /  230W |    5598MiB /  24564MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             507      C   /python3.12                           N/A      |\n",
      "|    1   N/A  N/A             507      C   /python3.12                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbd282-bf30-4184-92d7-7d332c743c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50da93e7-2b3a-4126-a1b6-fa574ed0aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards: 100%|██████████| 2/2 [04:01<00:00, 120.88s/it]\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText \n",
    "import torch \n",
    "\n",
    "model_path = \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\" \n",
    "processor = AutoProcessor.from_pretrained(model_path) \n",
    "model = AutoModelForImageTextToText.from_pretrained(model_path, torch_dtype=torch.bfloat16, _attn_implementation=\"flash_attention_2\").to(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb98ac5a-7cdb-454c-8c01-ac6dc7300336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 22 01:45:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.16              Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  |   00000000:15:00.0  On |                  Off |\n",
      "| 30%   43C    P8             16W /  230W |    5556MiB /  24564MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000               On  |   00000000:99:00.0 Off |                  Off |\n",
      "| 30%   43C    P8             13W /  230W |    5556MiB /  24564MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           11909      C   /python3.12                           N/A      |\n",
      "|    1   N/A  N/A           11909      C   /python3.12                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2df3c3-79fd-4190-9c43-f9a1982ee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"role\": \"user\", \"content\": [ {\"type\": \"video\", \"path\": \"Music.mp4\"}, {\"type\": \"text\", \"text\": \"Describe this video in detail\"} ] },]\n",
    "\n",
    "inputs = processor.apply_chat_template( messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\", ).to(model.device, torch.bfloat16) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83abd810-abe5-44c7-89c8-4187594ce326",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=564) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbac5393-0ca5-4dca-aea5-5e5c529539c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts = processor.batch_decode( generated_ids, skip_special_tokens=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0bc92d-c636-4593-9203-4c7627e289d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: You are provided the following series of sixty-four frames from a 0:02:22 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:03:\\nFrame from 00:05:\\nFrame from 00:07:\\nFrame from 00:09:\\nFrame from 00:12:\\nFrame from 00:14:\\nFrame from 00:16:\\nFrame from 00:18:\\nFrame from 00:21:\\nFrame from 00:23:\\nFrame from 00:25:\\nFrame from 00:27:\\nFrame from 00:29:\\nFrame from 00:32:\\nFrame from 00:34:\\nFrame from 00:36:\\nFrame from 00:38:\\nFrame from 00:41:\\nFrame from 00:43:\\nFrame from 00:45:\\nFrame from 00:47:\\nFrame from 00:50:\\nFrame from 00:52:\\nFrame from 00:54:\\nFrame from 00:56:\\nFrame from 00:58:\\nFrame from 01:01:\\nFrame from 01:03:\\nFrame from 01:05:\\nFrame from 01:07:\\nFrame from 01:10:\\nFrame from 01:12:\\nFrame from 01:14:\\nFrame from 01:16:\\nFrame from 01:18:\\nFrame from 01:21:\\nFrame from 01:23:\\nFrame from 01:25:\\nFrame from 01:27:\\nFrame from 01:30:\\nFrame from 01:32:\\nFrame from 01:34:\\nFrame from 01:36:\\nFrame from 01:39:\\nFrame from 01:41:\\nFrame from 01:43:\\nFrame from 01:45:\\nFrame from 01:47:\\nFrame from 01:50:\\nFrame from 01:52:\\nFrame from 01:54:\\nFrame from 01:56:\\nFrame from 01:59:\\nFrame from 02:01:\\nFrame from 02:03:\\nFrame from 02:05:\\nFrame from 02:08:\\nFrame from 02:10:\\nFrame from 02:12:\\nFrame from 02:14:\\nFrame from 02:17:\\nFrame from 02:19:\\nFrame from 02:21:\\n\\nDescribe this video in detail\\nAssistant: The video opens with a serene view of a lush, green forest, transitioning to a panoramic view of a mountainous landscape under a clear blue sky. The camera then shifts to a closer view of the mountains, highlighting the dense forest and the expansive green field below. A solitary figure appears in the distance, walking towards the camera, eventually standing in the center of the frame, surrounded by the natural beauty of the mountains and forest. The person, dressed in a black top and a long, gray skirt, stands still, looking out at the expansive view. The camera zooms in on the person, capturing their profile and the serene environment. The person then moves closer to the camera, standing in the center of the frame, with the mountains and forest in the background. The person appears to be speaking or singing, with their arms outstretched, adding a sense of movement and emotion to the scene. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the surrounding landscape. The person then moves to stand in front of a line of birch trees, appearing contemplative and reflective. The camera captures the person from different angles, emphasizing their posture and the']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cdbb5e5-ec0e-4ebe-a83e-a8a1d939f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Extract the item names from this invoice. please do not include unit price and total amount. provide the name in list\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b586d19d-8acb-4cd4-8e3c-ed87e13475c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('invoice.png').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67d4da55-e2af-49f5-ac3b-3501e813cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [{\"role\": \"user\",\"content\": [{\"type\": \"text\", \"text\": prompt},{\"type\": \"image\" ,\"path\": image},]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "641953b1-d43c-49be-bbc4-86ed2fc196ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor.apply_chat_template( messages, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\", ).to(model.device, torch.bfloat16) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc57c44e-7e2d-40a2-927c-037cdffcc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25962731-6052-4d6f-82e4-58d109f6fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts = processor.batch_decode( generated_ids, skip_special_tokens=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c1ca41-481c-468e-8672-59cc10bfd5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \n",
      "Extract the item names from this invoice. please do not include unit price and total amount. provide the name in list\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Assistant: The item names from the invoice are:\n",
      "- Front and rear brake cables\n",
      "- New set of pedal arms\n",
      "- Labor 3 hours\n"
     ]
    }
   ],
   "source": [
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da4085-cb45-4c88-b932-fa41446f5714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
